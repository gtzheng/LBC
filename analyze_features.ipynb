{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler\n",
    "import numpy as np\n",
    "from deep_feature_reweighting.wb_data import (\n",
    "    WaterBirdsDataset,\n",
    "    get_loader,\n",
    "    get_transform_cub,\n",
    ")\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdxDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (idx, *self.dataset[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/gz5hp/ml/lib/python3.10/site-packages/torchvision/transforms/transforms.py:899: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11788\n",
      "4795\n",
      "11788\n",
      "4795\n",
      "11788\n",
      "5794\n"
     ]
    }
   ],
   "source": [
    "DATA_FOLDER = \"/bigtemp/gz5hp/dataset_hub/waterbird_complete95_forest2water2\"\n",
    "CONCEPT_PATH = \"/bigtemp/gz5hp/dataset_hub/waterbird_complete95_forest2water2/img_embeddings_thre10_vocab144.pickle\"\n",
    "VOCAB_PATH = \"/bigtemp/gz5hp/dataset_hub/waterbird_complete95_forest2water2/vocab_thre10_144.pickle\"\n",
    "batch_size = 128\n",
    "train_transform = get_transform_cub(\n",
    "        target_resolution=(224, 224), train=True, augment_data=True\n",
    "    )\n",
    "test_transform = get_transform_cub(\n",
    "    target_resolution=(224, 224), train=False, augment_data=False\n",
    ")\n",
    "trainset = WaterBirdsDataset(\n",
    "        basedir=DATA_FOLDER,\n",
    "        split=\"train\",\n",
    "        transform=train_transform,\n",
    "        concept_embed=CONCEPT_PATH\n",
    "    )\n",
    "trainset_ref = WaterBirdsDataset(\n",
    "        basedir=DATA_FOLDER,\n",
    "        split=\"train\",\n",
    "        transform=test_transform,\n",
    "        concept_embed=CONCEPT_PATH\n",
    "    )\n",
    "train_idx_dataset = IdxDataset(trainset_ref)\n",
    "train_loader = DataLoader(\n",
    "                trainset,\n",
    "                batch_size=batch_size,\n",
    "                pin_memory=True,\n",
    "                num_workers=4,\n",
    "            )\n",
    "ref_train_loader = DataLoader(\n",
    "                train_idx_dataset,\n",
    "                batch_size=batch_size,\n",
    "                pin_memory=True,\n",
    "                num_workers=4,\n",
    "            )\n",
    "\n",
    "testset = WaterBirdsDataset(\n",
    "    basedir=DATA_FOLDER,\n",
    "    split=\"test\",\n",
    "    transform=test_transform,\n",
    "    concept_embed=CONCEPT_PATH\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "                testset,\n",
    "                batch_size=batch_size,\n",
    "                pin_memory=True,\n",
    "                num_workers=4,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device  = \"cuda:0\"\n",
    "model = torchvision.models.resnet50(weights=None)\n",
    "d = model.fc.in_features\n",
    "model.fc = torch.nn.Linear(d, 2)\n",
    "ckpt_path = \"/bigtemp/gz5hp/spurious_correlations/dfr_ckpts/waterbirds/erm_seed1/final_checkpoint.pt\"\n",
    "model.load_state_dict(torch.load(ckpt_path))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correlated_features(model, dataloader):\n",
    "    class_wise_data = {}\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx, data, y, _, _, _ in tqdm(dataloader):\n",
    "            logits = model(data.to(device))\n",
    "            logits = logits.detach().cpu()\n",
    "            preds = torch.argmax(logits, dim=1).numpy()\n",
    "            for i in range(len(y)):\n",
    "                l = y[i].item()\n",
    "                if l in class_wise_data:\n",
    "                    class_wise_data[l].append((idx[i].item(),int(preds[i]==l)))\n",
    "                else:\n",
    "                    class_wise_data[l] = [(idx[i].item(),int(preds[i]==l))]\n",
    "    embeddings = dataloader.dataset.dataset.embeddings  \n",
    "    class_correlated_feas = {}\n",
    "    for c in class_wise_data:\n",
    "        num_per_class = len(class_wise_data[c])\n",
    "        counts_pos_w = np.zeros(embeddings.shape[1])\n",
    "        counts_neg_w = np.zeros(embeddings.shape[1])\n",
    "        \n",
    "        counts_pos_wo = np.zeros(embeddings.shape[1])\n",
    "        counts_neg_wo = np.zeros(embeddings.shape[1])\n",
    "        for idx, pred_res in class_wise_data[c]:\n",
    "            if pred_res == 1:\n",
    "                counts_pos_w[embeddings[idx] == 1] += 1\n",
    "                counts_pos_wo[embeddings[idx] != 1] += 1\n",
    "            else:\n",
    "                counts_neg_w[embeddings[idx] == 1] += 1\n",
    "                counts_neg_wo[embeddings[idx] != 1] += 1\n",
    "                \n",
    "            \n",
    "        indexes = np.arange(embeddings.shape[1])\n",
    "        active_feas = indexes[(counts_pos_w + counts_neg_w) > 0]\n",
    "        total_w = counts_pos_w[active_feas] + counts_neg_w[active_feas]\n",
    "        probs_w = counts_pos_w[active_feas] / total_w\n",
    "        \n",
    "        total_wo = counts_pos_wo[active_feas] + counts_neg_wo[active_feas]\n",
    "        probs_wo = counts_pos_wo[active_feas] / (total_wo + 1e-10)\n",
    "        \n",
    "        scores = np.tanh(abs(np.log(probs_w / (probs_wo+1e-10)+1e-10)))\n",
    "        class_correlated_feas[c] = (scores, active_feas)\n",
    "    return class_correlated_feas      \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(VOCAB_PATH, \"rb\") as f:\n",
    "    vocab = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:10<00:00,  3.60it/s]\n"
     ]
    }
   ],
   "source": [
    "class_correlated_feas = get_correlated_features(model, ref_train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['white:adj',\n",
       " 'large:adj',\n",
       " 'bird:noun',\n",
       " 'top:noun',\n",
       " 'duck:noun',\n",
       " 'person:noun',\n",
       " 'beach:noun',\n",
       " 'black:adj',\n",
       " 'water:noun',\n",
       " 'woman:noun',\n",
       " 'seagull:noun',\n",
       " 'body:noun',\n",
       " 'colorful:adj',\n",
       " 'flower:noun',\n",
       " 'bike:noun',\n",
       " 'pole:noun',\n",
       " 'head:noun',\n",
       " 'dirt:noun',\n",
       " 'post:noun',\n",
       " 'dirt road:noun',\n",
       " 'elephant:noun',\n",
       " 'giraffe:noun',\n",
       " 'picnic:noun',\n",
       " 'flower pot:noun',\n",
       " 'beak:noun',\n",
       " 'long:adj',\n",
       " 'picnic table:noun',\n",
       " 'metal:noun',\n",
       " 'city:noun',\n",
       " 'bunch:noun',\n",
       " 'pot:noun',\n",
       " 'sidewalk:noun',\n",
       " 'red:adj',\n",
       " 'leave:noun',\n",
       " 'skateboard:noun',\n",
       " 'horse:noun',\n",
       " 'ground:noun',\n",
       " 'boy:noun',\n",
       " 'wall:noun',\n",
       " 'back:noun',\n",
       " 'grass field:noun',\n",
       " 'wood:noun',\n",
       " 'waterfall:noun',\n",
       " 'polar:adj',\n",
       " 'sand:noun',\n",
       " 'table:noun',\n",
       " 'crowd:noun',\n",
       " 'ledge:noun',\n",
       " 'day:noun',\n",
       " 'mountain:noun',\n",
       " 'hillside:noun',\n",
       " 'cat:noun',\n",
       " 'bridge:noun',\n",
       " 'umbrella:noun',\n",
       " 'fish:noun',\n",
       " 'palm tree:noun',\n",
       " 'palm:noun',\n",
       " 'dry:adj',\n",
       " 'sky:noun',\n",
       " 'flock:noun',\n",
       " 'blue:adj',\n",
       " 'mouth:noun',\n",
       " 'side:noun',\n",
       " 'little:adj',\n",
       " 'wooden:adj',\n",
       " 'girl:noun',\n",
       " 'road:noun',\n",
       " 'fence:noun',\n",
       " 'log:noun',\n",
       " 'snow:noun',\n",
       " 'penguin:noun',\n",
       " 'frisbee:noun',\n",
       " 'bench:noun',\n",
       " 'statue:noun',\n",
       " 'dock:noun',\n",
       " 'dog:noun',\n",
       " 'wave:noun',\n",
       " 'pier:noun',\n",
       " 'grass:noun',\n",
       " 'lush:adj',\n",
       " 'green:adj',\n",
       " 'field:noun',\n",
       " 'surfboard:noun',\n",
       " 'ocean:noun',\n",
       " 'boat:noun',\n",
       " 'sandy:adj',\n",
       " 'man:noun',\n",
       " 'rock:noun',\n",
       " 'pond:noun',\n",
       " 'kite:noun',\n",
       " 'people:noun',\n",
       " 'yellow:adj',\n",
       " 'hand:noun',\n",
       " 'lake:noun',\n",
       " 'brown:adj',\n",
       " 'air:noun',\n",
       " 'small:adj',\n",
       " 'group:noun',\n",
       " 'river:noun',\n",
       " 'edge:noun',\n",
       " 'tree branch:noun',\n",
       " 'bear:noun',\n",
       " 'branch:noun',\n",
       " 'tree:noun',\n",
       " 'photo:noun',\n",
       " 'animal:noun',\n",
       " 'middle:noun',\n",
       " 'front:noun',\n",
       " 'building:noun',\n",
       " 'pile:noun',\n",
       " 'forest:noun',\n",
       " 'stream:noun',\n",
       " 'dead:adj',\n",
       " 'limb:noun',\n",
       " 'tree limb:noun',\n",
       " 'parrot:noun']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fea_indexes = class_correlated_feas[1][1][np.argsort(class_correlated_feas[1][0])]\n",
    "[vocab[i] for i in fea_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 116 artists>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(np.arange(len(class_correlated_feas[1][0])), np.sort(class_correlated_feas[1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UnlearnModel(\n",
       "  (backbone): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): IdentityModel()\n",
       "  )\n",
       "  (classifier): Linear(in_features=2048, out_features=2, bias=True)\n",
       "  (fea_decoder): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=256, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "class IdentityModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(IdentityModel, self).__init__()\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "class UnlearnModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UnlearnModel, self).__init__()\n",
    "        model = torchvision.models.resnet50(weights=None)\n",
    "        d = model.fc.in_features\n",
    "        identity_layer = IdentityModel()\n",
    "        self.backbone = model\n",
    "        self.backbone.fc = identity_layer\n",
    "        \n",
    "        self.classifier = nn.Linear(d, 2)\n",
    "        self.fea_decoder = nn.Sequential(nn.Linear(d, 256), nn.ReLU(), nn.Linear(256, 2))\n",
    "    def unlearn(self, x):\n",
    "        with torch.no_grad():\n",
    "            fea = self.backbone(x)\n",
    "        dec = self.fea_decoder(fea)\n",
    "        return dec\n",
    "    def forward(self, x):\n",
    "        fea = self.backbone(x)\n",
    "        dec = self.fea_decoder(fea)\n",
    "        logits = self.classifier(fea)\n",
    "        return logits, dec\n",
    "umodel = UnlearnModel()\n",
    "umodel.backbone.load_state_dict(torch.load(ckpt_path), strict=False)\n",
    "umodel.to(device)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "           \n",
    "class DecoderDataset(Dataset):\n",
    "    def __init__(self, dataset, feature_indexes):\n",
    "        self.dataset = dataset\n",
    "        all_indexes = np.arange(len(dataset.embeddings))\n",
    "        sel_indexes = []\n",
    "        labels = []\n",
    "        features = []\n",
    "        for c in feature_indexes:\n",
    "            features.append(feature_indexes[c])\n",
    "        features = np.unique(np.concatenate(features))\n",
    "        self.labels = np.zeros(len(all_indexes),dtype=np.int64)\n",
    "        cond = dataset.embeddings[:,features].sum(axis=1) > 0\n",
    "        indexes = all_indexes[cond]\n",
    "        self.labels[indexes] = 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset[idx][0], self.labels[idx]\n",
    "\n",
    "\n",
    "# learn the feature decoder\n",
    "fea_indexes = {}\n",
    "for c in class_correlated_feas:\n",
    "    indexes = class_correlated_feas[c][1][np.argsort(class_correlated_feas[c][0])]\n",
    "    fea_indexes[c] = indexes[-10:]\n",
    "decoder_dataset = DecoderDataset(trainset, fea_indexes)\n",
    "decoder_train_loader = DataLoader(\n",
    "                decoder_dataset,\n",
    "                batch_size=batch_size,\n",
    "                pin_memory=True,\n",
    "                num_workers=4,\n",
    "            )\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:08<00:00,  4.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss 0.0045 acc_avg 0.6813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:07<00:00,  4.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss 0.0037 acc_avg 0.8121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:08<00:00,  4.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 loss 0.0035 acc_avg 0.8257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:07<00:00,  4.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 loss 0.0035 acc_avg 0.8288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:08<00:00,  4.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 loss 0.0034 acc_avg 0.8300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:08<00:00,  4.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 loss 0.0034 acc_avg 0.8298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:08<00:00,  4.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 loss 0.0034 acc_avg 0.8313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:07<00:00,  4.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 loss 0.0034 acc_avg 0.8313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:08<00:00,  4.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 loss 0.0034 acc_avg 0.8338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:07<00:00,  4.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 loss 0.0034 acc_avg 0.8346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:08<00:00,  4.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 loss 0.0033 acc_avg 0.8338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:07<00:00,  4.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 loss 0.0033 acc_avg 0.8365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:08<00:00,  4.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 loss 0.0033 acc_avg 0.8359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:07<00:00,  4.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 loss 0.0033 acc_avg 0.8386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:08<00:00,  4.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 loss 0.0033 acc_avg 0.8375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:07<00:00,  4.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 loss 0.0033 acc_avg 0.8375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:08<00:00,  4.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 loss 0.0032 acc_avg 0.8386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:07<00:00,  4.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 loss 0.0032 acc_avg 0.8409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:08<00:00,  4.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 loss 0.0032 acc_avg 0.8409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:07<00:00,  4.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 loss 0.0032 acc_avg 0.8423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:08<00:00,  4.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 loss 0.0032 acc_avg 0.8415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 26/38 [00:05<00:02,  5.11it/s]"
     ]
    }
   ],
   "source": [
    "umodel.eval()\n",
    "umodel.fea_decoder.train()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "decoder_optimizer = torch.optim.SGD(\n",
    "        umodel.fea_decoder.parameters(), lr=5.e-4, momentum=0.9, weight_decay=1e-4\n",
    ")\n",
    "for epoch in range(50):\n",
    "    loss_avg = 0.0\n",
    "    acc_avg = 0.0\n",
    "    counts = 0\n",
    "    for data, y in tqdm(decoder_train_loader):\n",
    "        data = data.to(device)\n",
    "        y = y.to(device)\n",
    "        dec = umodel.unlearn(data)\n",
    "        loss = loss_func(dec, y)\n",
    "        decoder_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        decoder_optimizer.step()\n",
    "        loss_avg += loss.item()\n",
    "        counts += len(y)\n",
    "        corrects = (torch.argmax(dec, dim=1) == y).sum().item()\n",
    "        acc_avg += corrects\n",
    "    acc_avg /= counts\n",
    "    loss_avg /= counts\n",
    "    print(f\"Epoch {epoch} loss {loss_avg:.4f} acc_avg {acc_avg:.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:17<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss 0.0050 acc_avg 0.7791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:17<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss 0.0045 acc_avg 0.7677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:17<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 loss 0.0044 acc_avg 0.7679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:17<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 loss 0.0043 acc_avg 0.7679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:17<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 loss 0.0042 acc_avg 0.7679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:17<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 loss 0.0041 acc_avg 0.7691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:17<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 loss 0.0041 acc_avg 0.7731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:17<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 loss 0.0040 acc_avg 0.7773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:17<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 loss 0.0040 acc_avg 0.7860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:17<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 loss 0.0039 acc_avg 0.7975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:17<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 loss 0.0039 acc_avg 0.8113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:17<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 loss 0.0038 acc_avg 0.8190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:17<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 loss 0.0038 acc_avg 0.8317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:17<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 loss 0.0038 acc_avg 0.8413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:17<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 loss 0.0037 acc_avg 0.8473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:17<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 loss 0.0037 acc_avg 0.8540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:17<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 loss 0.0037 acc_avg 0.8599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:17<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 loss 0.0037 acc_avg 0.8651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:17<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 loss 0.0036 acc_avg 0.8669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:17<00:00,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 loss 0.0036 acc_avg 0.8690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#unlearn the selected features\n",
    "umodel.train()\n",
    "umodel.fea_decoder.eval()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(\n",
    "        list(umodel.backbone.parameters())+list(umodel.classifier.parameters()), lr=1.e-5, momentum=0.9, weight_decay=1e-4\n",
    ")\n",
    "for epoch in range(50):\n",
    "    loss_avg = 0.0\n",
    "    acc_avg = 0.0\n",
    "    counts = 0\n",
    "    for data, y, _, _, _ in tqdm(train_loader):\n",
    "        data = data.to(device)\n",
    "        y = y.to(device)\n",
    "        ref_y = (torch.ones(len(y),2)/2.0).to(device)\n",
    "        logits, dec = umodel(data)\n",
    "        loss1 = loss_func(logits, y)\n",
    "        loss2 = loss_func(dec, ref_y)\n",
    "        loss = loss1 + loss2 * 0.1\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_avg += loss.item()\n",
    "        counts += len(y)\n",
    "        corrects = (torch.argmax(logits, dim=1) == y).sum().item()\n",
    "        acc_avg += corrects\n",
    "    acc_avg /= counts\n",
    "    loss_avg /= counts\n",
    "    print(f\"Epoch {epoch} loss {loss_avg:.4f} acc_avg {acc_avg:.4f}\")\n",
    "umodel.fea_decoder.train()\n",
    "loss_func = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, loader):\n",
    "    count = 0\n",
    "    acc = 0\n",
    "    model.eval()\n",
    "    res = []\n",
    "    groups = []\n",
    "    with torch.no_grad():\n",
    "        for x, y, g, p, _ in loader:\n",
    "            x, y = (\n",
    "                x.to(device),\n",
    "                y.to(device),\n",
    "            )  # 1 for water; 0 for land. 1 for seabird; 0 for landbird.\n",
    "            out, _ = model(x)\n",
    "            pred = (torch.argmax(out, dim=-1) == y).detach().cpu().numpy()\n",
    "            res.append(pred)\n",
    "            groups.append(g.detach().cpu().numpy())\n",
    "    res = np.concatenate(res)\n",
    "    groups = np.concatenate(groups)\n",
    "    avg_acc = res.sum() / len(res)\n",
    "    acc_group = []\n",
    "    group_num = []\n",
    "    for g in np.unique(groups):\n",
    "        gres = res[groups == g]\n",
    "        acc_group.append(gres.sum() / len(gres))\n",
    "        group_num.append(len(gres))\n",
    "    acc_group = np.array(acc_group)\n",
    "    worst_acc = acc_group.min()\n",
    "    # print(group_num)\n",
    "    return avg_acc, worst_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_acc 0.9261 worst_acc 0.5935\n"
     ]
    }
   ],
   "source": [
    "avg_acc, worst_acc = test_model(umodel, test_loader)\n",
    "print(f\"avg_acc {avg_acc:.4f} worst_acc {worst_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single decoder layer: avg_acc 0.9113 worst_acc 0.5576 (20, 20)\n",
    "# two-layer decoder: avg_acc 0.9261 worst_acc 0.5935 (20, 20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
