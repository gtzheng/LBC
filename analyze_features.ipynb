{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler\n",
    "import numpy as np\n",
    "from deep_feature_reweighting.wb_data import (\n",
    "    WaterBirdsDataset,\n",
    "    get_loader,\n",
    "    get_transform_cub,\n",
    ")\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdxDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (idx, *self.dataset[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11788\n",
      "4795\n",
      "11788\n",
      "4795\n",
      "11788\n",
      "5794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/gz5hp/ml/lib/python3.10/site-packages/torchvision/transforms/transforms.py:899: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "DATA_FOLDER = \"/bigtemp/gz5hp/dataset_hub/waterbird_complete95_forest2water2\"\n",
    "CONCEPT_PATH = \"/bigtemp/gz5hp/dataset_hub/waterbird_complete95_forest2water2/img_embeddings_thre10_vocab144.pickle\"\n",
    "VOCAB_PATH = \"/bigtemp/gz5hp/dataset_hub/waterbird_complete95_forest2water2/vocab_thre10_144.pickle\"\n",
    "batch_size = 128\n",
    "train_transform = get_transform_cub(\n",
    "        target_resolution=(224, 224), train=True, augment_data=True\n",
    "    )\n",
    "test_transform = get_transform_cub(\n",
    "    target_resolution=(224, 224), train=False, augment_data=False\n",
    ")\n",
    "trainset = WaterBirdsDataset(\n",
    "        basedir=DATA_FOLDER,\n",
    "        split=\"train\",\n",
    "        transform=train_transform,\n",
    "        concept_embed=CONCEPT_PATH\n",
    "    )\n",
    "trainset_ref = WaterBirdsDataset(\n",
    "        basedir=DATA_FOLDER,\n",
    "        split=\"train\",\n",
    "        transform=test_transform,\n",
    "        concept_embed=CONCEPT_PATH\n",
    "    )\n",
    "train_idx_dataset = IdxDataset(trainset_ref)\n",
    "train_loader = DataLoader(\n",
    "                trainset,\n",
    "                batch_size=batch_size,\n",
    "                pin_memory=True,\n",
    "                num_workers=4,\n",
    "            )\n",
    "ref_train_loader = DataLoader(\n",
    "                train_idx_dataset,\n",
    "                batch_size=batch_size,\n",
    "                pin_memory=True,\n",
    "                num_workers=4,\n",
    "            )\n",
    "\n",
    "testset = WaterBirdsDataset(\n",
    "    basedir=DATA_FOLDER,\n",
    "    split=\"test\",\n",
    "    transform=test_transform,\n",
    "    concept_embed=CONCEPT_PATH\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "                testset,\n",
    "                batch_size=batch_size,\n",
    "                pin_memory=True,\n",
    "                num_workers=4,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device  = \"cuda:0\"\n",
    "model = torchvision.models.resnet50(weights=None)\n",
    "d = model.fc.in_features\n",
    "model.fc = torch.nn.Linear(d, 2)\n",
    "ckpt_path = \"/bigtemp/gz5hp/spurious_correlations/dfr_ckpts/waterbirds/erm_seed1/final_checkpoint.pt\"\n",
    "model.load_state_dict(torch.load(ckpt_path))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correlated_features(model, dataloader):\n",
    "    class_wise_data = {}\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx, data, y, _, _, _ in tqdm(dataloader):\n",
    "            logits = model(data.to(device))\n",
    "            logits = logits.detach().cpu()\n",
    "            preds = torch.argmax(logits, dim=1).numpy()\n",
    "            for i in range(len(y)):\n",
    "                l = y[i].item()\n",
    "                if l in class_wise_data:\n",
    "                    class_wise_data[l].append((idx[i].item(),int(preds[i]==l)))\n",
    "                else:\n",
    "                    class_wise_data[l] = [(idx[i].item(),int(preds[i]==l))]\n",
    "    embeddings = dataloader.dataset.dataset.embeddings  \n",
    "    class_correlated_feas = {}\n",
    "    for c in class_wise_data:\n",
    "        num_per_class = len(class_wise_data[c])\n",
    "        counts_pos_w = np.zeros(embeddings.shape[1])\n",
    "        counts_neg_w = np.zeros(embeddings.shape[1])\n",
    "        \n",
    "        counts_pos_wo = np.zeros(embeddings.shape[1])\n",
    "        counts_neg_wo = np.zeros(embeddings.shape[1])\n",
    "        for idx, pred_res in class_wise_data[c]:\n",
    "            if pred_res == 1:\n",
    "                counts_pos_w[embeddings[idx] == 1] += 1\n",
    "                counts_pos_wo[embeddings[idx] != 1] += 1\n",
    "            else:\n",
    "                counts_neg_w[embeddings[idx] == 1] += 1\n",
    "                counts_neg_wo[embeddings[idx] != 1] += 1\n",
    "                \n",
    "            \n",
    "        indexes = np.arange(embeddings.shape[1])\n",
    "        active_feas = indexes[(counts_pos_w + counts_neg_w) > 0]\n",
    "        total_w = counts_pos_w[active_feas] + counts_neg_w[active_feas]\n",
    "        probs_w = counts_pos_w[active_feas] / total_w\n",
    "        \n",
    "        total_wo = counts_pos_wo[active_feas] + counts_neg_wo[active_feas]\n",
    "        probs_wo = counts_pos_wo[active_feas] / (total_wo + 1e-10)\n",
    "        \n",
    "        scores = np.tanh(abs(np.log(probs_w / (probs_wo+1e-10)+1e-10)))\n",
    "        class_correlated_feas[c] = (scores, active_feas)\n",
    "    return class_correlated_feas      \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(VOCAB_PATH, \"rb\") as f:\n",
    "    vocab = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:08<00:00,  4.63it/s]\n"
     ]
    }
   ],
   "source": [
    "class_correlated_feas = get_correlated_features(model, ref_train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['white:adj',\n",
       " 'large:adj',\n",
       " 'bird:noun',\n",
       " 'top:noun',\n",
       " 'duck:noun',\n",
       " 'person:noun',\n",
       " 'beach:noun',\n",
       " 'black:adj',\n",
       " 'water:noun',\n",
       " 'woman:noun',\n",
       " 'seagull:noun',\n",
       " 'body:noun',\n",
       " 'colorful:adj',\n",
       " 'flower:noun',\n",
       " 'bike:noun',\n",
       " 'pole:noun',\n",
       " 'head:noun',\n",
       " 'dirt:noun',\n",
       " 'post:noun',\n",
       " 'dirt road:noun',\n",
       " 'elephant:noun',\n",
       " 'giraffe:noun',\n",
       " 'picnic:noun',\n",
       " 'flower pot:noun',\n",
       " 'beak:noun',\n",
       " 'long:adj',\n",
       " 'picnic table:noun',\n",
       " 'metal:noun',\n",
       " 'city:noun',\n",
       " 'bunch:noun',\n",
       " 'pot:noun',\n",
       " 'sidewalk:noun',\n",
       " 'red:adj',\n",
       " 'leave:noun',\n",
       " 'skateboard:noun',\n",
       " 'horse:noun',\n",
       " 'ground:noun',\n",
       " 'boy:noun',\n",
       " 'wall:noun',\n",
       " 'back:noun',\n",
       " 'grass field:noun',\n",
       " 'wood:noun',\n",
       " 'waterfall:noun',\n",
       " 'polar:adj',\n",
       " 'sand:noun',\n",
       " 'table:noun',\n",
       " 'crowd:noun',\n",
       " 'ledge:noun',\n",
       " 'day:noun',\n",
       " 'mountain:noun',\n",
       " 'hillside:noun',\n",
       " 'cat:noun',\n",
       " 'bridge:noun',\n",
       " 'umbrella:noun',\n",
       " 'fish:noun',\n",
       " 'palm tree:noun',\n",
       " 'palm:noun',\n",
       " 'dry:adj',\n",
       " 'sky:noun',\n",
       " 'flock:noun',\n",
       " 'blue:adj',\n",
       " 'mouth:noun',\n",
       " 'side:noun',\n",
       " 'little:adj',\n",
       " 'wooden:adj',\n",
       " 'girl:noun',\n",
       " 'road:noun',\n",
       " 'fence:noun',\n",
       " 'log:noun',\n",
       " 'snow:noun',\n",
       " 'penguin:noun',\n",
       " 'frisbee:noun',\n",
       " 'bench:noun',\n",
       " 'statue:noun',\n",
       " 'dock:noun',\n",
       " 'dog:noun',\n",
       " 'wave:noun',\n",
       " 'pier:noun',\n",
       " 'grass:noun',\n",
       " 'lush:adj',\n",
       " 'green:adj',\n",
       " 'field:noun',\n",
       " 'surfboard:noun',\n",
       " 'ocean:noun',\n",
       " 'boat:noun',\n",
       " 'sandy:adj',\n",
       " 'man:noun',\n",
       " 'rock:noun',\n",
       " 'pond:noun',\n",
       " 'kite:noun',\n",
       " 'people:noun',\n",
       " 'yellow:adj',\n",
       " 'hand:noun',\n",
       " 'lake:noun',\n",
       " 'brown:adj',\n",
       " 'air:noun',\n",
       " 'small:adj',\n",
       " 'group:noun',\n",
       " 'river:noun',\n",
       " 'edge:noun',\n",
       " 'tree branch:noun',\n",
       " 'bear:noun',\n",
       " 'branch:noun',\n",
       " 'tree:noun',\n",
       " 'photo:noun',\n",
       " 'animal:noun',\n",
       " 'middle:noun',\n",
       " 'front:noun',\n",
       " 'building:noun',\n",
       " 'pile:noun',\n",
       " 'forest:noun',\n",
       " 'stream:noun',\n",
       " 'dead:adj',\n",
       " 'limb:noun',\n",
       " 'tree limb:noun',\n",
       " 'parrot:noun']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fea_indexes = class_correlated_feas[1][1][np.argsort(class_correlated_feas[1][0])]\n",
    "[vocab[i] for i in fea_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 116 artists>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(np.arange(len(class_correlated_feas[1][0])), np.sort(class_correlated_feas[1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "           \n",
    "class DecoderDataset(Dataset):\n",
    "    def __init__(self, dataset, feature_indexes):\n",
    "        self.dataset = dataset\n",
    "        all_indexes = np.arange(len(dataset.embeddings))\n",
    "        sel_indexes = []\n",
    "        labels = []\n",
    "        features = []\n",
    "        for c in feature_indexes:\n",
    "            features.append(feature_indexes[c])\n",
    "        features = np.unique(np.concatenate(features))\n",
    "        # self.labels = np.zeros(len(all_indexes),dtype=np.int64)\n",
    "        # cond = dataset.embeddings[:,features].sum(axis=1) > 0\n",
    "        # indexes = all_indexes[cond]\n",
    "        # self.labels[indexes] = 1\n",
    "        self.labels = dataset.embeddings[:,features].astype(np.int64)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset[idx][0], self.labels[idx]\n",
    "\n",
    "\n",
    "# learn the feature decoder\n",
    "fea_indexes = {}\n",
    "for c in class_correlated_feas:\n",
    "    indexes = class_correlated_feas[c][1][np.argsort(class_correlated_feas[c][0])]\n",
    "    fea_indexes[c] = indexes[-10:]\n",
    "decoder_dataset = DecoderDataset(trainset, fea_indexes)\n",
    "decoder_train_loader = DataLoader(\n",
    "                decoder_dataset,\n",
    "                batch_size=batch_size,\n",
    "                pin_memory=True,\n",
    "                num_workers=4,\n",
    "            )\n",
    "num_heads = decoder_dataset.labels.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UnlearnModel(\n",
       "  (backbone): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): IdentityModel()\n",
       "  )\n",
       "  (classifier): Linear(in_features=2048, out_features=2, bias=True)\n",
       "  (fea_decoder): ModuleList(\n",
       "    (0): Linear(in_features=2048, out_features=2, bias=True)\n",
       "    (1): Linear(in_features=2048, out_features=2, bias=True)\n",
       "    (2): Linear(in_features=2048, out_features=2, bias=True)\n",
       "    (3): Linear(in_features=2048, out_features=2, bias=True)\n",
       "    (4): Linear(in_features=2048, out_features=2, bias=True)\n",
       "    (5): Linear(in_features=2048, out_features=2, bias=True)\n",
       "    (6): Linear(in_features=2048, out_features=2, bias=True)\n",
       "    (7): Linear(in_features=2048, out_features=2, bias=True)\n",
       "    (8): Linear(in_features=2048, out_features=2, bias=True)\n",
       "    (9): Linear(in_features=2048, out_features=2, bias=True)\n",
       "    (10): Linear(in_features=2048, out_features=2, bias=True)\n",
       "    (11): Linear(in_features=2048, out_features=2, bias=True)\n",
       "    (12): Linear(in_features=2048, out_features=2, bias=True)\n",
       "    (13): Linear(in_features=2048, out_features=2, bias=True)\n",
       "    (14): Linear(in_features=2048, out_features=2, bias=True)\n",
       "    (15): Linear(in_features=2048, out_features=2, bias=True)\n",
       "    (16): Linear(in_features=2048, out_features=2, bias=True)\n",
       "    (17): Linear(in_features=2048, out_features=2, bias=True)\n",
       "    (18): Linear(in_features=2048, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class IdentityModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(IdentityModel, self).__init__()\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "class UnlearnModel(nn.Module):\n",
    "    def __init__(self, num_heads):\n",
    "        super(UnlearnModel, self).__init__()\n",
    "        model = torchvision.models.resnet50(weights=None)\n",
    "        d = model.fc.in_features\n",
    "        identity_layer = IdentityModel()\n",
    "        self.backbone = model\n",
    "        self.backbone.fc = identity_layer\n",
    "        \n",
    "        self.classifier = nn.Linear(d, 2)\n",
    "        self.fea_decoder = nn.ModuleList([nn.Linear(d, 2) for n in range(num_heads)])\n",
    "        self.num_heads = num_heads\n",
    "    def unlearn(self, x):\n",
    "        with torch.no_grad():\n",
    "            fea = self.backbone(x)\n",
    "        decs = []\n",
    "        for n in range(self.num_heads):\n",
    "            dec = self.fea_decoder[n](fea)\n",
    "            decs.append(dec)\n",
    "        return decs\n",
    "    def forward(self, x):\n",
    "        fea = self.backbone(x)\n",
    "        decs = []\n",
    "        for n in range(self.num_heads):\n",
    "            dec = self.fea_decoder[n](fea)\n",
    "            decs.append(dec)\n",
    "        logits = self.classifier(fea)\n",
    "        return logits, decs\n",
    "umodel = UnlearnModel(num_heads)\n",
    "umodel.backbone.load_state_dict(torch.load(ckpt_path), strict=False)\n",
    "umodel.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:08<00:00,  4.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss 0.0201 acc_avg 0.9578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:08<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss 0.0121 acc_avg 0.9759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:08<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 loss 0.0108 acc_avg 0.9765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:08<00:00,  4.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 loss 0.0104 acc_avg 0.9769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:08<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 loss 0.0101 acc_avg 0.9773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:08<00:00,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 loss 0.0099 acc_avg 0.9776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:08<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 loss 0.0097 acc_avg 0.9777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:08<00:00,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 loss 0.0096 acc_avg 0.9778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:08<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 loss 0.0095 acc_avg 0.9783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:08<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 loss 0.0094 acc_avg 0.9783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:08<00:00,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 loss 0.0093 acc_avg 0.9785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:08<00:00,  4.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 loss 0.0092 acc_avg 0.9785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:08<00:00,  4.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 loss 0.0092 acc_avg 0.9787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:08<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 loss 0.0090 acc_avg 0.9790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:08<00:00,  4.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 loss 0.0091 acc_avg 0.9786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:08<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 loss 0.0089 acc_avg 0.9791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:08<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 loss 0.0089 acc_avg 0.9789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:08<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 loss 0.0089 acc_avg 0.9789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:08<00:00,  4.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 loss 0.0089 acc_avg 0.9793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:08<00:00,  4.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 loss 0.0088 acc_avg 0.9795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "umodel.eval()\n",
    "umodel.fea_decoder.train()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "decoder_optimizer = torch.optim.SGD(\n",
    "        umodel.fea_decoder.parameters(), lr=1.e-3, momentum=0.9, weight_decay=1e-4\n",
    ")\n",
    "for epoch in range(20):\n",
    "    loss_avg = 0.0\n",
    "    acc_avg = np.zeros(num_heads)\n",
    "    counts = 0\n",
    "    for data, y in tqdm(decoder_train_loader):\n",
    "        data = data.to(device)\n",
    "        y = y.to(device)\n",
    "        decs = umodel.unlearn(data)\n",
    "        loss = 0.0\n",
    "        for n in range(len(decs)):\n",
    "            loss += loss_func(decs[n], y[:,n])\n",
    "        decoder_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        decoder_optimizer.step()\n",
    "        loss_avg += loss.item()\n",
    "        counts += len(y)\n",
    "        for n in range(len(decs)):\n",
    "            acc_avg[n] += (torch.argmax(decs[n], dim=1) == y[:,n]).sum().item()\n",
    "    acc_avg /= counts\n",
    "    loss_avg /= counts\n",
    "    print(f\"Epoch {epoch} loss {loss_avg:.4f} acc_avg {acc_avg.mean():.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:17<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss 0.0060 acc_avg 0.7668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:17<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss 0.0060 acc_avg 0.7662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:18<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 loss 0.0060 acc_avg 0.7666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:18<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 loss 0.0060 acc_avg 0.7670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:17<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 loss 0.0060 acc_avg 0.7670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:18<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 loss 0.0060 acc_avg 0.7666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:17<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 loss 0.0060 acc_avg 0.7668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:17<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 loss 0.0059 acc_avg 0.7668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:18<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 loss 0.0059 acc_avg 0.7664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:17<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 loss 0.0059 acc_avg 0.7677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:18<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 loss 0.0059 acc_avg 0.7673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:17<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 loss 0.0059 acc_avg 0.7664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:18<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 loss 0.0059 acc_avg 0.7668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:17<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 loss 0.0059 acc_avg 0.7673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:18<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 loss 0.0059 acc_avg 0.7673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:17<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 loss 0.0059 acc_avg 0.7668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:18<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 loss 0.0059 acc_avg 0.7675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:17<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 loss 0.0059 acc_avg 0.7668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:17<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 loss 0.0058 acc_avg 0.7675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:17<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 loss 0.0058 acc_avg 0.7673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:18<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 loss 0.0058 acc_avg 0.7666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:17<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 loss 0.0058 acc_avg 0.7666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:18<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 loss 0.0058 acc_avg 0.7666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:17<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 loss 0.0058 acc_avg 0.7670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:17<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 loss 0.0058 acc_avg 0.7677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:17<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 loss 0.0058 acc_avg 0.7666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:18<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 loss 0.0058 acc_avg 0.7668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:17<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 loss 0.0058 acc_avg 0.7675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:17<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 loss 0.0058 acc_avg 0.7666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:17<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 loss 0.0058 acc_avg 0.7673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:17<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 loss 0.0058 acc_avg 0.7675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:17<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 loss 0.0058 acc_avg 0.7670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:17<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 loss 0.0057 acc_avg 0.7670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:17<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 loss 0.0058 acc_avg 0.7668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:17<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 loss 0.0057 acc_avg 0.7670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:18<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 loss 0.0057 acc_avg 0.7668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:18<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 loss 0.0057 acc_avg 0.7666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:18<00:00,  2.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 loss 0.0057 acc_avg 0.7673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:18<00:00,  2.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 loss 0.0057 acc_avg 0.7673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:18<00:00,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 loss 0.0057 acc_avg 0.7675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:18<00:00,  2.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 loss 0.0057 acc_avg 0.7664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:18<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 loss 0.0057 acc_avg 0.7664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:18<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 loss 0.0057 acc_avg 0.7664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:18<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 loss 0.0057 acc_avg 0.7670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:18<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 loss 0.0057 acc_avg 0.7670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:18<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 loss 0.0057 acc_avg 0.7673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:18<00:00,  2.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 loss 0.0057 acc_avg 0.7670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:18<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 loss 0.0056 acc_avg 0.7666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:18<00:00,  2.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 loss 0.0057 acc_avg 0.7666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:18<00:00,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 loss 0.0056 acc_avg 0.7670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#unlearn the selected features\n",
    "umodel.train()\n",
    "umodel.fea_decoder.eval()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(\n",
    "        list(umodel.backbone.parameters())+list(umodel.classifier.parameters()), lr=1.e-5, momentum=0.9, weight_decay=1e-4\n",
    ")\n",
    "for epoch in range(50):\n",
    "    loss_avg = 0.0\n",
    "    acc_avg = 0.0\n",
    "    counts = 0\n",
    "    for data, y, _, _, _ in tqdm(train_loader):\n",
    "        data = data.to(device)\n",
    "        y = y.to(device)\n",
    "        ref_y = (torch.ones(len(y),2)/2.0).to(device)\n",
    "        logits, decs = umodel(data)\n",
    "        loss1 = loss_func(logits, y)\n",
    "        loss2 = 0.0\n",
    "        for n in range(len(decs)):\n",
    "            loss2 += loss_func(decs[n], ref_y)\n",
    "\n",
    "        loss = loss1 + loss2/num_heads * 0.2\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_avg += loss.item()\n",
    "        counts += len(y)\n",
    "        corrects = (torch.argmax(logits, dim=1) == y).sum().item()\n",
    "        acc_avg += corrects\n",
    "    acc_avg /= counts\n",
    "    loss_avg /= counts\n",
    "    print(f\"Epoch {epoch} loss {loss_avg:.4f} acc_avg {acc_avg:.4f}\")\n",
    "umodel.fea_decoder.train()\n",
    "loss_func = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, loader):\n",
    "    count = 0\n",
    "    acc = 0\n",
    "    model.eval()\n",
    "    res = []\n",
    "    groups = []\n",
    "    with torch.no_grad():\n",
    "        for x, y, g, p, _ in loader:\n",
    "            x, y = (\n",
    "                x.to(device),\n",
    "                y.to(device),\n",
    "            )  # 1 for water; 0 for land. 1 for seabird; 0 for landbird.\n",
    "            out, _ = model(x)\n",
    "            pred = (torch.argmax(out, dim=-1) == y).detach().cpu().numpy()\n",
    "            res.append(pred)\n",
    "            groups.append(g.detach().cpu().numpy())\n",
    "    res = np.concatenate(res)\n",
    "    groups = np.concatenate(groups)\n",
    "    avg_acc = res.sum() / len(res)\n",
    "    acc_group = []\n",
    "    group_num = []\n",
    "    for g in np.unique(groups):\n",
    "        gres = res[groups == g]\n",
    "        acc_group.append(gres.sum() / len(gres))\n",
    "        group_num.append(len(gres))\n",
    "    acc_group = np.array(acc_group)\n",
    "    worst_acc = acc_group.min()\n",
    "    # print(group_num)\n",
    "    return avg_acc, worst_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_acc 0.9165 worst_acc 0.7648\n"
     ]
    }
   ],
   "source": [
    "avg_acc, worst_acc = test_model(umodel, test_loader)\n",
    "print(f\"avg_acc {avg_acc:.4f} worst_acc {worst_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single decoder layer: avg_acc 0.9113 worst_acc 0.5576 (20, 20), alpha = 0.1\n",
    "# two-layer decoder: avg_acc 0.9261 worst_acc 0.5935 (20, 20), alpha = 0.1\n",
    "# two-layer decoder (256 hidden units): avg_acc 0.9115 worst_acc 0.7819 (50, 50)-epoch, alpha = 0.1\n",
    "# two-layer decoder (512 hidden units): avg_acc 0.9104 worst_acc 0.7586 (50, 50)-epoch, alpha = 0.1\n",
    "# two-layer decoder (256 hidden units): avg_acc 0.9213 worst_acc 0.7928 (50, 50)-epoch, alpha = 0.2\n",
    "# two-layer decoder (256 hidden units): avg_acc 0.9239 worst_acc 0.7866, alpha = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11787"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/bigtemp/gz5hp/dataset_hub/waterbird_complete95_forest2water2/vit-gpt2_captions.csv\"\n",
    "meta_path = \"/bigtemp/gz5hp/dataset_hub/waterbird_complete95_forest2water2/metadata.csv\"\n",
    "captions = [x.strip() for x in open(path, \"r\").readlines()]\n",
    "meta_data = [x.strip() for x in open(meta_path, \"r\").readlines()][1:]\n",
    "with open(\"/bigtemp/gz5hp/dataset_hub/waterbird_complete95_forest2water2/vit-gpt2_captions_new.csv\", \"w\") as f:\n",
    "    for i in range(len(meta_data)):\n",
    "        label = meta_data[i].split(',')[2].strip()\n",
    "        eles = captions[i].split(',')\n",
    "        sel_data = [eles[1].split('/')[-1], eles[-1], label]\n",
    "        f.write(','.join(sel_data)+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, '1', []),\n",
       " (1, '2', []),\n",
       " (2, '3', []),\n",
       " (3, '4', []),\n",
       " (4, '5', []),\n",
       " (5, '6', []),\n",
       " (6, '7', []),\n",
       " (7, '8', []),\n",
       " (8, '9', []),\n",
       " (9, '10', []),\n",
       " (10, '11', []),\n",
       " (11, '12', []),\n",
       " (12, '13', []),\n",
       " (13, '14', []),\n",
       " (14, '15', []),\n",
       " (15, '16', []),\n",
       " (16, '17', []),\n",
       " (17, '18', []),\n",
       " (18, '19', ['lake:noun']),\n",
       " (19, '20', []),\n",
       " (20, '21', []),\n",
       " (21, '22', []),\n",
       " (22, '23', ['lake:noun']),\n",
       " (23, '24', ['lake:noun']),\n",
       " (24, '25', ['lake:noun']),\n",
       " (25, '26', []),\n",
       " (26, '27', []),\n",
       " (27, '28', []),\n",
       " (28, '29', []),\n",
       " (29, '30', ['lake:noun']),\n",
       " (30, '31', []),\n",
       " (31, '32', []),\n",
       " (32, '33', []),\n",
       " (33, '34', []),\n",
       " (34, '35', []),\n",
       " (35, '36', []),\n",
       " (36, '37', []),\n",
       " (37, '38', []),\n",
       " (38, '39', []),\n",
       " (39, '40', []),\n",
       " (40, '41', []),\n",
       " (41, '42', []),\n",
       " (42, '43', []),\n",
       " (43, '44', []),\n",
       " (44, '45', []),\n",
       " (45, '46', []),\n",
       " (46, '47', []),\n",
       " (47, '48', []),\n",
       " (48, '49', []),\n",
       " (49, '50', []),\n",
       " (50, '51', []),\n",
       " (51, '52', []),\n",
       " (52, '53', []),\n",
       " (53, '54', []),\n",
       " (54, '55', []),\n",
       " (55, '56', []),\n",
       " (56, '57', []),\n",
       " (57, '58', []),\n",
       " (58, '59', []),\n",
       " (59, '60', []),\n",
       " (60, '61', []),\n",
       " (61, '62', []),\n",
       " (62, '63', []),\n",
       " (63, '64', []),\n",
       " (64, '65', []),\n",
       " (65, '66', []),\n",
       " (66, '67', []),\n",
       " (67, '68', []),\n",
       " (68, '69', []),\n",
       " (69, '70', []),\n",
       " (70, '71', []),\n",
       " (71, '72', []),\n",
       " (72, '73', []),\n",
       " (73, '74', []),\n",
       " (74, '75', []),\n",
       " (75, '76', []),\n",
       " (76, '77', []),\n",
       " (77, '78', []),\n",
       " (78, '79', []),\n",
       " (79, '80', []),\n",
       " (80, '81', []),\n",
       " (81, '82', []),\n",
       " (82, '83', []),\n",
       " (83, '84', []),\n",
       " (84, '85', []),\n",
       " (85, '86', []),\n",
       " (86, '87', []),\n",
       " (87, '88', []),\n",
       " (88, '89', []),\n",
       " (89, '90', []),\n",
       " (90, '91', []),\n",
       " (91, '92', []),\n",
       " (92, '93', []),\n",
       " (93, '94', []),\n",
       " (94, '95', []),\n",
       " (95, '96', []),\n",
       " (96, '97', []),\n",
       " (97, '98', []),\n",
       " (98, '99', []),\n",
       " (99, '100', []),\n",
       " (100, '101', []),\n",
       " (101, '102', []),\n",
       " (102, '103', []),\n",
       " (103, '104', []),\n",
       " (104, '105', []),\n",
       " (105, '106', []),\n",
       " (106, '107', []),\n",
       " (107, '108', []),\n",
       " (108, '109', []),\n",
       " (109, '110', []),\n",
       " (110, '111', []),\n",
       " (111, '112', []),\n",
       " (112, '113', []),\n",
       " (113, '114', []),\n",
       " (114, '115', []),\n",
       " (115, '116', []),\n",
       " (116, '117', []),\n",
       " (117, '118', []),\n",
       " (118, '119', []),\n",
       " (119, '120', []),\n",
       " (120, '121', []),\n",
       " (121, '122', []),\n",
       " (122, '123', []),\n",
       " (123, '124', []),\n",
       " (124, '125', []),\n",
       " (125, '126', []),\n",
       " (126, '127', []),\n",
       " (127, '128', []),\n",
       " (128, '129', []),\n",
       " (129, '130', []),\n",
       " (130, '131', []),\n",
       " (131, '132', []),\n",
       " (132, '133', []),\n",
       " (133, '134', []),\n",
       " (134, '135', []),\n",
       " (135, '136', []),\n",
       " (136, '137', []),\n",
       " (137, '138', []),\n",
       " (138, '139', []),\n",
       " (139, '140', []),\n",
       " (140, '141', []),\n",
       " (141, '142', []),\n",
       " (142, '143', []),\n",
       " (143, '144', []),\n",
       " (144, '145', []),\n",
       " (145, '146', []),\n",
       " (146, '147', []),\n",
       " (147, '148', []),\n",
       " (148, '149', []),\n",
       " (149, '150', []),\n",
       " (150, '151', []),\n",
       " (151, '152', []),\n",
       " (152, '153', []),\n",
       " (153, '154', []),\n",
       " (154, '155', []),\n",
       " (155, '156', []),\n",
       " (156, '157', []),\n",
       " (157, '158', []),\n",
       " (158, '159', []),\n",
       " (159, '160', []),\n",
       " (160, '161', []),\n",
       " (161, '162', []),\n",
       " (162, '163', []),\n",
       " (163, '164', []),\n",
       " (164, '165', []),\n",
       " (165, '166', []),\n",
       " (166, '167', []),\n",
       " (167, '168', []),\n",
       " (168, '169', []),\n",
       " (169, '170', []),\n",
       " (170, '171', []),\n",
       " (171, '172', []),\n",
       " (172, '173', []),\n",
       " (173, '174', []),\n",
       " (174, '175', []),\n",
       " (175, '176', []),\n",
       " (176, '177', []),\n",
       " (177, '178', []),\n",
       " (178, '179', []),\n",
       " (179, '180', []),\n",
       " (180, '181', []),\n",
       " (181, '182', []),\n",
       " (182, '183', []),\n",
       " (183, '184', []),\n",
       " (184, '185', []),\n",
       " (185, '186', []),\n",
       " (186, '187', []),\n",
       " (187, '188', []),\n",
       " (188, '189', []),\n",
       " (189, '190', []),\n",
       " (190, '191', []),\n",
       " (191, '192', []),\n",
       " (192, '193', []),\n",
       " (193, '194', []),\n",
       " (194, '195', []),\n",
       " (195, '196', []),\n",
       " (196, '197', []),\n",
       " (197, '198', []),\n",
       " (198, '199', []),\n",
       " (199, '200', []),\n",
       " (200, '201', []),\n",
       " (201, '202', []),\n",
       " (202, '203', []),\n",
       " (203, '204', []),\n",
       " (204, '205', []),\n",
       " (205, '206', []),\n",
       " (206, '207', []),\n",
       " (207, '208', []),\n",
       " (208, '209', []),\n",
       " (209, '210', []),\n",
       " (210, '211', []),\n",
       " (211, '212', []),\n",
       " (212, '213', []),\n",
       " (213, '214', []),\n",
       " (214, '215', []),\n",
       " (215, '216', []),\n",
       " (216, '217', []),\n",
       " (217, '218', []),\n",
       " (218, '219', []),\n",
       " (219, '220', []),\n",
       " (220, '221', []),\n",
       " (221, '222', []),\n",
       " (222, '223', []),\n",
       " (223, '224', []),\n",
       " (224, '225', []),\n",
       " (225, '226', []),\n",
       " (226, '227', []),\n",
       " (227, '228', []),\n",
       " (228, '229', []),\n",
       " (229, '230', []),\n",
       " (230, '231', []),\n",
       " (231, '232', []),\n",
       " (232, '233', []),\n",
       " (233, '234', []),\n",
       " (234, '235', []),\n",
       " (235, '236', []),\n",
       " (236, '237', []),\n",
       " (237, '238', []),\n",
       " (238, '239', []),\n",
       " (239, '240', []),\n",
       " (240, '241', ['lake:noun']),\n",
       " (241, '242', []),\n",
       " (242, '243', ['lake:noun']),\n",
       " (243, '244', []),\n",
       " (244, '245', ['lake:noun']),\n",
       " (245, '246', []),\n",
       " (246, '247', []),\n",
       " (247, '248', []),\n",
       " (248, '249', ['lake:noun']),\n",
       " (249, '250', ['lake:noun']),\n",
       " (250, '251', []),\n",
       " (251, '252', []),\n",
       " (252, '253', []),\n",
       " (253, '254', []),\n",
       " (254, '255', []),\n",
       " (255, '256', []),\n",
       " (256, '257', []),\n",
       " (257, '258', []),\n",
       " (258, '259', []),\n",
       " (259, '260', ['lake:noun']),\n",
       " (260, '261', ['lake:noun']),\n",
       " (261, '262', []),\n",
       " (262, '263', ['lake:noun']),\n",
       " (263, '264', []),\n",
       " (264, '265', []),\n",
       " (265, '266', ['lake:noun']),\n",
       " (266, '267', ['lake:noun']),\n",
       " (267, '268', ['lake:noun']),\n",
       " (268, '269', ['lake:noun']),\n",
       " (269, '270', []),\n",
       " (270, '271', []),\n",
       " (271, '272', ['lake:noun']),\n",
       " (272, '273', []),\n",
       " (273, '274', []),\n",
       " (274, '275', ['lake:noun']),\n",
       " (275, '276', []),\n",
       " (276, '277', ['lake:noun']),\n",
       " (277, '278', ['lake:noun']),\n",
       " (278, '279', []),\n",
       " (279, '280', []),\n",
       " (280, '281', ['lake:noun']),\n",
       " (281, '282', []),\n",
       " (282, '283', []),\n",
       " (283, '284', []),\n",
       " (284, '285', []),\n",
       " (285, '286', []),\n",
       " (286, '287', []),\n",
       " (287, '288', []),\n",
       " (288, '289', []),\n",
       " (289, '290', []),\n",
       " (290, '291', []),\n",
       " (291, '292', []),\n",
       " (292, '293', []),\n",
       " (293, '294', []),\n",
       " (294, '295', []),\n",
       " (295, '296', []),\n",
       " (296, '297', []),\n",
       " (297, '298', []),\n",
       " (298, '299', []),\n",
       " (299, '300', []),\n",
       " (300, '301', []),\n",
       " (301, '302', []),\n",
       " (302, '303', []),\n",
       " (303, '304', []),\n",
       " (304, '305', []),\n",
       " (305, '306', []),\n",
       " (306, '307', []),\n",
       " (307, '308', []),\n",
       " (308, '309', []),\n",
       " (309, '310', []),\n",
       " (310, '311', []),\n",
       " (311, '312', []),\n",
       " (312, '313', []),\n",
       " (313, '314', []),\n",
       " (314, '315', []),\n",
       " (315, '316', []),\n",
       " (316, '317', []),\n",
       " (317, '318', []),\n",
       " (318, '319', []),\n",
       " (319, '320', []),\n",
       " (320, '321', []),\n",
       " (321, '322', []),\n",
       " (322, '323', []),\n",
       " (323, '324', []),\n",
       " (324, '325', []),\n",
       " (325, '326', []),\n",
       " (326, '327', ['lake:noun']),\n",
       " (327, '328', []),\n",
       " (328, '329', []),\n",
       " (329, '330', []),\n",
       " (330, '331', ['lake:noun']),\n",
       " (331, '332', []),\n",
       " (332, '333', ['lake:noun']),\n",
       " (333, '334', []),\n",
       " (334, '335', []),\n",
       " (335, '336', []),\n",
       " (336, '337', []),\n",
       " (337, '338', []),\n",
       " (338, '339', []),\n",
       " (339, '340', []),\n",
       " (340, '341', []),\n",
       " (341, '342', ['lake:noun']),\n",
       " (342, '343', []),\n",
       " (343, '344', []),\n",
       " (344, '345', []),\n",
       " (345, '346', []),\n",
       " (346, '347', ['lake:noun']),\n",
       " (347, '348', []),\n",
       " (348, '349', []),\n",
       " (349, '350', []),\n",
       " (350, '351', []),\n",
       " (351, '352', []),\n",
       " (352, '353', ['lake:noun']),\n",
       " (353, '354', []),\n",
       " (354, '355', []),\n",
       " (355, '356', []),\n",
       " (356, '357', []),\n",
       " (357, '358', []),\n",
       " (358, '359', []),\n",
       " (359, '360', []),\n",
       " (360, '361', []),\n",
       " (361, '362', ['lake:noun']),\n",
       " (362, '363', []),\n",
       " (363, '364', []),\n",
       " (364, '365', []),\n",
       " (365, '366', ['lake:noun']),\n",
       " (366, '367', []),\n",
       " (367, '368', []),\n",
       " (368, '369', []),\n",
       " (369, '370', []),\n",
       " (370, '371', []),\n",
       " (371, '372', []),\n",
       " (372, '373', []),\n",
       " (373, '374', []),\n",
       " (374, '375', []),\n",
       " (375, '376', []),\n",
       " (376, '377', []),\n",
       " (377, '378', ['lake:noun']),\n",
       " (378, '379', []),\n",
       " (379, '380', ['lake:noun']),\n",
       " (380, '381', ['lake:noun']),\n",
       " (381, '382', []),\n",
       " (382, '383', ['lake:noun']),\n",
       " (383, '384', ['lake:noun']),\n",
       " (384, '385', []),\n",
       " (385, '386', []),\n",
       " (386, '387', []),\n",
       " (387, '388', ['lake:noun']),\n",
       " (388, '389', ['lake:noun']),\n",
       " (389, '390', ['lake:noun']),\n",
       " (390, '391', []),\n",
       " (391, '392', ['lake:noun']),\n",
       " (392, '393', []),\n",
       " (393, '394', []),\n",
       " (394, '395', ['lake:noun']),\n",
       " (395, '396', []),\n",
       " (396, '397', []),\n",
       " (397, '398', []),\n",
       " (398, '399', ['lake:noun']),\n",
       " (399, '400', []),\n",
       " (400, '401', ['lake:noun']),\n",
       " (401, '402', []),\n",
       " (402, '403', []),\n",
       " (403, '404', []),\n",
       " (404, '405', []),\n",
       " (405, '406', ['lake:noun']),\n",
       " (406, '407', []),\n",
       " (407, '408', []),\n",
       " (408, '409', ['lake:noun']),\n",
       " (409, '410', ['lake:noun']),\n",
       " (410, '411', []),\n",
       " (411, '412', []),\n",
       " (412, '413', []),\n",
       " (413, '414', []),\n",
       " (414, '415', []),\n",
       " (415, '416', []),\n",
       " (416, '417', []),\n",
       " (417, '418', ['lake:noun']),\n",
       " (418, '419', []),\n",
       " (419, '420', []),\n",
       " (420, '421', ['lake:noun']),\n",
       " (421, '422', []),\n",
       " (422, '423', []),\n",
       " (423, '424', []),\n",
       " (424, '425', []),\n",
       " (425, '426', []),\n",
       " (426, '427', []),\n",
       " (427, '428', []),\n",
       " (428, '429', []),\n",
       " (429, '430', []),\n",
       " (430, '431', []),\n",
       " (431, '432', []),\n",
       " (432, '433', []),\n",
       " (433, '434', []),\n",
       " (434, '435', []),\n",
       " (435, '436', []),\n",
       " (436, '437', []),\n",
       " (437, '438', []),\n",
       " (438, '439', []),\n",
       " (439, '440', []),\n",
       " (440, '441', []),\n",
       " (441, '442', []),\n",
       " (442, '443', []),\n",
       " (443, '444', []),\n",
       " (444, '445', []),\n",
       " (445, '446', []),\n",
       " (446, '447', []),\n",
       " (447, '448', []),\n",
       " (448, '449', []),\n",
       " (449, '450', []),\n",
       " (450, '451', []),\n",
       " (451, '452', []),\n",
       " (452, '453', []),\n",
       " (453, '454', []),\n",
       " (454, '455', []),\n",
       " (455, '456', []),\n",
       " (456, '457', []),\n",
       " (457, '458', []),\n",
       " (458, '459', []),\n",
       " (459, '460', []),\n",
       " (460, '461', []),\n",
       " (461, '462', []),\n",
       " (462, '463', []),\n",
       " (463, '464', []),\n",
       " (464, '465', []),\n",
       " (465, '466', []),\n",
       " (466, '467', []),\n",
       " (467, '468', []),\n",
       " (468, '469', []),\n",
       " (469, '470', []),\n",
       " (470, '471', []),\n",
       " (471, '472', []),\n",
       " (472, '473', []),\n",
       " (473, '474', []),\n",
       " (474, '475', []),\n",
       " (475, '476', []),\n",
       " (476, '477', []),\n",
       " (477, '478', []),\n",
       " (478, '479', []),\n",
       " (479, '480', []),\n",
       " (480, '481', []),\n",
       " (481, '482', []),\n",
       " (482, '483', []),\n",
       " (483, '484', []),\n",
       " (484, '485', []),\n",
       " (485, '486', []),\n",
       " (486, '487', []),\n",
       " (487, '488', []),\n",
       " (488, '489', []),\n",
       " (489, '490', []),\n",
       " (490, '491', []),\n",
       " (491, '492', []),\n",
       " (492, '493', []),\n",
       " (493, '494', []),\n",
       " (494, '495', []),\n",
       " (495, '496', []),\n",
       " (496, '497', []),\n",
       " (497, '498', []),\n",
       " (498, '499', []),\n",
       " (499, '500', []),\n",
       " (500, '501', []),\n",
       " (501, '502', []),\n",
       " (502, '503', []),\n",
       " (503, '504', []),\n",
       " (504, '505', []),\n",
       " (505, '506', []),\n",
       " (506, '507', []),\n",
       " (507, '508', []),\n",
       " (508, '509', []),\n",
       " (509, '510', []),\n",
       " (510, '511', []),\n",
       " (511, '512', []),\n",
       " (512, '513', []),\n",
       " (513, '514', []),\n",
       " (514, '515', []),\n",
       " (515, '516', []),\n",
       " (516, '517', []),\n",
       " (517, '518', []),\n",
       " (518, '519', []),\n",
       " (519, '520', []),\n",
       " (520, '521', []),\n",
       " (521, '522', []),\n",
       " (522, '523', []),\n",
       " (523, '524', []),\n",
       " (524, '525', []),\n",
       " (525, '526', []),\n",
       " (526, '527', []),\n",
       " (527, '528', []),\n",
       " (528, '529', []),\n",
       " (529, '530', []),\n",
       " (530, '531', []),\n",
       " (531, '532', []),\n",
       " (532, '533', []),\n",
       " (533, '534', []),\n",
       " (534, '535', []),\n",
       " (535, '536', []),\n",
       " (536, '537', []),\n",
       " (537, '538', []),\n",
       " (538, '539', []),\n",
       " (539, '540', []),\n",
       " (540, '541', []),\n",
       " (541, '542', []),\n",
       " (542, '543', []),\n",
       " (543, '544', []),\n",
       " (544, '545', []),\n",
       " (545, '546', []),\n",
       " (546, '547', []),\n",
       " (547, '548', []),\n",
       " (548, '549', []),\n",
       " (549, '550', []),\n",
       " (550, '551', []),\n",
       " (551, '552', []),\n",
       " (552, '553', []),\n",
       " (553, '554', []),\n",
       " (554, '555', []),\n",
       " (555, '556', []),\n",
       " (556, '557', []),\n",
       " (557, '558', []),\n",
       " (558, '559', []),\n",
       " (559, '560', []),\n",
       " (560, '561', []),\n",
       " (561, '562', []),\n",
       " (562, '563', []),\n",
       " (563, '564', []),\n",
       " (564, '565', []),\n",
       " (565, '566', []),\n",
       " (566, '567', []),\n",
       " (567, '568', []),\n",
       " (568, '569', []),\n",
       " (569, '570', []),\n",
       " (570, '571', []),\n",
       " (571, '572', []),\n",
       " (572, '573', []),\n",
       " (573, '574', []),\n",
       " (574, '575', []),\n",
       " (575, '576', []),\n",
       " (576, '577', []),\n",
       " (577, '578', []),\n",
       " (578, '579', []),\n",
       " (579, '580', []),\n",
       " (580, '581', []),\n",
       " (581, '582', []),\n",
       " (582, '583', []),\n",
       " (583, '584', []),\n",
       " (584, '585', []),\n",
       " (585, '586', []),\n",
       " (586, '587', []),\n",
       " (587, '588', []),\n",
       " (588, '589', []),\n",
       " (589, '590', []),\n",
       " (590, '591', []),\n",
       " (591, '592', []),\n",
       " (592, '593', []),\n",
       " (593, '594', []),\n",
       " (594, '595', []),\n",
       " (595, '596', []),\n",
       " (596, '597', []),\n",
       " (597, '598', []),\n",
       " (598, '599', []),\n",
       " (599, '600', []),\n",
       " (600, '601', []),\n",
       " (601, '602', []),\n",
       " (602, '603', []),\n",
       " (603, '604', []),\n",
       " (604, '605', []),\n",
       " (605, '606', []),\n",
       " (606, '607', []),\n",
       " (607, '608', []),\n",
       " (608, '609', []),\n",
       " (609, '610', []),\n",
       " (610, '611', []),\n",
       " (611, '612', []),\n",
       " (612, '613', []),\n",
       " (613, '614', []),\n",
       " (614, '615', []),\n",
       " (615, '616', []),\n",
       " (616, '617', []),\n",
       " (617, '618', []),\n",
       " (618, '619', []),\n",
       " (619, '620', []),\n",
       " (620, '621', []),\n",
       " (621, '622', []),\n",
       " (622, '623', []),\n",
       " (623, '624', []),\n",
       " (624, '625', []),\n",
       " (625, '626', []),\n",
       " (626, '627', []),\n",
       " (627, '628', []),\n",
       " (628, '629', []),\n",
       " (629, '630', []),\n",
       " (630, '631', []),\n",
       " (631, '632', []),\n",
       " (632, '633', []),\n",
       " (633, '634', []),\n",
       " (634, '635', []),\n",
       " (635, '636', []),\n",
       " (636, '637', []),\n",
       " (637, '638', []),\n",
       " (638, '639', []),\n",
       " (639, '640', []),\n",
       " (640, '641', []),\n",
       " (641, '642', []),\n",
       " (642, '643', []),\n",
       " (643, '644', []),\n",
       " (644, '645', []),\n",
       " (645, '646', []),\n",
       " (646, '647', []),\n",
       " (647, '648', []),\n",
       " (648, '649', []),\n",
       " (649, '650', []),\n",
       " (650, '651', []),\n",
       " (651, '652', []),\n",
       " (652, '653', []),\n",
       " (653, '654', []),\n",
       " (654, '655', []),\n",
       " (655, '656', []),\n",
       " (656, '657', []),\n",
       " (657, '658', []),\n",
       " (658, '659', []),\n",
       " (659, '660', []),\n",
       " (660, '661', []),\n",
       " (661, '662', []),\n",
       " (662, '663', []),\n",
       " (663, '664', []),\n",
       " (664, '665', []),\n",
       " (665, '666', []),\n",
       " (666, '667', []),\n",
       " (667, '668', []),\n",
       " (668, '669', []),\n",
       " (669, '670', []),\n",
       " (670, '671', []),\n",
       " (671, '672', []),\n",
       " (672, '673', []),\n",
       " (673, '674', []),\n",
       " (674, '675', []),\n",
       " (675, '676', []),\n",
       " (676, '677', []),\n",
       " (677, '678', []),\n",
       " (678, '679', []),\n",
       " (679, '680', []),\n",
       " (680, '681', []),\n",
       " (681, '682', []),\n",
       " (682, '683', []),\n",
       " (683, '684', []),\n",
       " (684, '685', []),\n",
       " (685, '686', []),\n",
       " (686, '687', []),\n",
       " (687, '688', []),\n",
       " (688, '689', []),\n",
       " (689, '690', []),\n",
       " (690, '691', []),\n",
       " (691, '692', []),\n",
       " (692, '693', []),\n",
       " (693, '694', []),\n",
       " (694, '695', []),\n",
       " (695, '696', []),\n",
       " (696, '697', []),\n",
       " (697, '698', []),\n",
       " (698, '699', []),\n",
       " (699, '700', []),\n",
       " (700, '701', []),\n",
       " (701, '702', []),\n",
       " (702, '703', []),\n",
       " (703, '704', []),\n",
       " (704, '705', []),\n",
       " (705, '706', []),\n",
       " (706, '707', []),\n",
       " (707, '708', []),\n",
       " (708, '709', []),\n",
       " (709, '710', []),\n",
       " (710, '711', []),\n",
       " (711, '712', []),\n",
       " (712, '713', []),\n",
       " (713, '714', []),\n",
       " (714, '715', []),\n",
       " (715, '716', []),\n",
       " (716, '717', []),\n",
       " (717, '718', []),\n",
       " (718, '719', []),\n",
       " (719, '720', []),\n",
       " (720, '721', []),\n",
       " (721, '722', []),\n",
       " (722, '723', []),\n",
       " (723, '724', []),\n",
       " (724, '725', []),\n",
       " (725, '726', []),\n",
       " (726, '727', []),\n",
       " (727, '728', []),\n",
       " (728, '729', []),\n",
       " (729, '730', []),\n",
       " (730, '731', []),\n",
       " (731, '732', []),\n",
       " (732, '733', []),\n",
       " (733, '734', []),\n",
       " (734, '735', []),\n",
       " (735, '736', []),\n",
       " (736, '737', []),\n",
       " (737, '738', []),\n",
       " (738, '739', []),\n",
       " (739, '740', []),\n",
       " (740, '741', []),\n",
       " (741, '742', []),\n",
       " (742, '743', []),\n",
       " (743, '744', []),\n",
       " (744, '745', []),\n",
       " (745, '746', []),\n",
       " (746, '747', []),\n",
       " (747, '748', []),\n",
       " (748, '749', []),\n",
       " (749, '750', []),\n",
       " (750, '751', []),\n",
       " (751, '752', []),\n",
       " (752, '753', []),\n",
       " (753, '754', []),\n",
       " (754, '755', []),\n",
       " (755, '756', []),\n",
       " (756, '757', []),\n",
       " (757, '758', []),\n",
       " (758, '759', []),\n",
       " (759, '760', []),\n",
       " (760, '761', []),\n",
       " (761, '762', []),\n",
       " (762, '763', []),\n",
       " (763, '764', []),\n",
       " (764, '765', []),\n",
       " (765, '766', []),\n",
       " (766, '767', []),\n",
       " (767, '768', []),\n",
       " (768, '769', []),\n",
       " (769, '770', []),\n",
       " (770, '771', []),\n",
       " (771, '772', []),\n",
       " (772, '773', []),\n",
       " (773, '774', []),\n",
       " (774, '775', []),\n",
       " (775, '776', []),\n",
       " (776, '777', []),\n",
       " (777, '778', []),\n",
       " (778, '779', []),\n",
       " (779, '780', []),\n",
       " (780, '781', []),\n",
       " (781, '782', []),\n",
       " (782, '783', []),\n",
       " (783, '784', []),\n",
       " (784, '785', []),\n",
       " (785, '786', []),\n",
       " (786, '787', []),\n",
       " (787, '788', []),\n",
       " (788, '789', []),\n",
       " (789, '790', []),\n",
       " (790, '791', []),\n",
       " (791, '792', []),\n",
       " (792, '793', []),\n",
       " (793, '794', []),\n",
       " (794, '795', []),\n",
       " (795, '796', []),\n",
       " (796, '797', []),\n",
       " (797, '798', []),\n",
       " (798, '799', []),\n",
       " (799, '800', []),\n",
       " (800, '801', []),\n",
       " (801, '802', []),\n",
       " (802, '803', []),\n",
       " (803, '804', []),\n",
       " (804, '805', []),\n",
       " (805, '806', []),\n",
       " (806, '807', []),\n",
       " (807, '808', []),\n",
       " (808, '809', []),\n",
       " (809, '810', []),\n",
       " (810, '811', []),\n",
       " (811, '812', []),\n",
       " (812, '813', []),\n",
       " (813, '814', []),\n",
       " (814, '815', []),\n",
       " (815, '816', []),\n",
       " (816, '817', []),\n",
       " (817, '818', []),\n",
       " (818, '819', []),\n",
       " (819, '820', []),\n",
       " (820, '821', []),\n",
       " (821, '822', []),\n",
       " (822, '823', []),\n",
       " (823, '824', []),\n",
       " (824, '825', []),\n",
       " (825, '826', []),\n",
       " (826, '827', []),\n",
       " (827, '828', []),\n",
       " (828, '829', []),\n",
       " (829, '830', []),\n",
       " (830, '831', []),\n",
       " (831, '832', []),\n",
       " (832, '833', []),\n",
       " (833, '834', []),\n",
       " (834, '835', []),\n",
       " (835, '836', []),\n",
       " (836, '837', []),\n",
       " (837, '838', []),\n",
       " (838, '839', []),\n",
       " (839, '840', []),\n",
       " (840, '841', []),\n",
       " (841, '842', []),\n",
       " (842, '843', []),\n",
       " (843, '844', []),\n",
       " (844, '845', []),\n",
       " (845, '846', []),\n",
       " (846, '847', []),\n",
       " (847, '848', []),\n",
       " (848, '849', []),\n",
       " (849, '850', []),\n",
       " (850, '851', []),\n",
       " (851, '852', []),\n",
       " (852, '853', []),\n",
       " (853, '854', []),\n",
       " (854, '855', []),\n",
       " (855, '856', []),\n",
       " (856, '857', []),\n",
       " (857, '858', []),\n",
       " (858, '859', []),\n",
       " (859, '860', []),\n",
       " (860, '861', []),\n",
       " (861, '862', []),\n",
       " (862, '863', []),\n",
       " (863, '864', []),\n",
       " (864, '865', []),\n",
       " (865, '866', []),\n",
       " (866, '867', []),\n",
       " (867, '868', []),\n",
       " (868, '869', []),\n",
       " (869, '870', []),\n",
       " (870, '871', []),\n",
       " (871, '872', []),\n",
       " (872, '873', []),\n",
       " (873, '874', []),\n",
       " (874, '875', []),\n",
       " (875, '876', []),\n",
       " (876, '877', []),\n",
       " (877, '878', []),\n",
       " (878, '879', []),\n",
       " (879, '880', []),\n",
       " (880, '881', []),\n",
       " (881, '882', []),\n",
       " (882, '883', []),\n",
       " (883, '884', []),\n",
       " (884, '885', []),\n",
       " (885, '886', []),\n",
       " (886, '887', []),\n",
       " (887, '888', []),\n",
       " (888, '889', []),\n",
       " (889, '890', []),\n",
       " (890, '891', []),\n",
       " (891, '892', []),\n",
       " (892, '893', []),\n",
       " (893, '894', []),\n",
       " (894, '895', []),\n",
       " (895, '896', []),\n",
       " (896, '897', []),\n",
       " (897, '898', []),\n",
       " (898, '899', []),\n",
       " (899, '900', []),\n",
       " (900, '901', []),\n",
       " (901, '902', []),\n",
       " (902, '903', []),\n",
       " (903, '904', []),\n",
       " (904, '905', []),\n",
       " (905, '906', []),\n",
       " (906, '907', []),\n",
       " (907, '908', []),\n",
       " (908, '909', []),\n",
       " (909, '910', []),\n",
       " (910, '911', []),\n",
       " (911, '912', []),\n",
       " (912, '913', []),\n",
       " (913, '914', []),\n",
       " (914, '915', []),\n",
       " (915, '916', []),\n",
       " (916, '917', []),\n",
       " (917, '918', []),\n",
       " (918, '919', []),\n",
       " (919, '920', []),\n",
       " (920, '921', []),\n",
       " (921, '922', []),\n",
       " (922, '923', []),\n",
       " (923, '924', []),\n",
       " (924, '925', []),\n",
       " (925, '926', []),\n",
       " (926, '927', []),\n",
       " (927, '928', []),\n",
       " (928, '929', []),\n",
       " (929, '930', []),\n",
       " (930, '931', []),\n",
       " (931, '932', []),\n",
       " (932, '933', []),\n",
       " (933, '934', []),\n",
       " (934, '935', []),\n",
       " (935, '936', []),\n",
       " (936, '937', []),\n",
       " (937, '938', []),\n",
       " (938, '939', []),\n",
       " (939, '940', []),\n",
       " (940, '941', []),\n",
       " (941, '942', []),\n",
       " (942, '943', []),\n",
       " (943, '944', []),\n",
       " (944, '945', []),\n",
       " (945, '946', []),\n",
       " (946, '947', []),\n",
       " (947, '948', []),\n",
       " (948, '949', []),\n",
       " (949, '950', []),\n",
       " (950, '951', []),\n",
       " (951, '952', []),\n",
       " (952, '953', []),\n",
       " (953, '954', []),\n",
       " (954, '955', []),\n",
       " (955, '956', []),\n",
       " (956, '957', []),\n",
       " (957, '958', []),\n",
       " (958, '959', []),\n",
       " (959, '960', []),\n",
       " (960, '961', []),\n",
       " (961, '962', []),\n",
       " (962, '963', []),\n",
       " (963, '964', []),\n",
       " (964, '965', []),\n",
       " (965, '966', []),\n",
       " (966, '967', []),\n",
       " (967, '968', []),\n",
       " (968, '969', []),\n",
       " (969, '970', []),\n",
       " (970, '971', []),\n",
       " (971, '972', []),\n",
       " (972, '973', []),\n",
       " (973, '974', []),\n",
       " (974, '975', []),\n",
       " (975, '976', []),\n",
       " (976, '977', []),\n",
       " (977, '978', []),\n",
       " (978, '979', []),\n",
       " (979, '980', []),\n",
       " (980, '981', []),\n",
       " (981, '982', []),\n",
       " (982, '983', []),\n",
       " (983, '984', []),\n",
       " (984, '985', []),\n",
       " (985, '986', []),\n",
       " (986, '987', []),\n",
       " (987, '988', []),\n",
       " (988, '989', []),\n",
       " (989, '990', []),\n",
       " (990, '991', []),\n",
       " (991, '992', []),\n",
       " (992, '993', []),\n",
       " (993, '994', []),\n",
       " (994, '995', []),\n",
       " (995, '996', []),\n",
       " (996, '997', []),\n",
       " (997, '998', []),\n",
       " (998, '999', []),\n",
       " (999, '1000', []),\n",
       " ...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concept_arr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
